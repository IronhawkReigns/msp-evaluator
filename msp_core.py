from fpdf import FPDF
from datetime import datetime
from fastapi import HTTPException
from typing import Any
import requests
import json
import uuid
from difflib import get_close_matches
from vector_writer import clova_embedding
import os
import chromadb
from chromadb import PersistentClient

# Embedding and collection setup
def query_embed(text: str):
    return clova_embedding(text)

CHROMA_PATH = os.path.abspath("chroma_store")
client = PersistentClient(path=CHROMA_PATH)
collection = client.get_or_create_collection("msp_chunks")

import anthropic
import os
from collections import defaultdict
import traceback
from fastapi import HTTPException

def run_msp_recommendation(question: str, min_score: int):
    """
    Sophisticated MSP recommendation leveraging Claude's analytical capabilities
    """
    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=20  # Increased for more comprehensive analysis
        )
        
        grouped_chunks = defaultdict(list)
        for meta in query_results["metadatas"][0]:
            if not isinstance(meta.get("answer"), str) or not meta["answer"].strip():
                continue
            if meta["score"] is not None and int(meta["score"]) >= min_score:
                grouped_chunks[meta["msp_name"]].append({
                    "question": meta['question'],
                    "answer": meta['answer'],
                    "score": meta['score'],
                    "category": meta.get('category', 'ë¯¸ë¶„ë¥˜'),
                    "group": meta.get('group', 'ê¸°íƒ€')
                })

        if not grouped_chunks:
            return {"answer": "í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” í‰ê°€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # Advanced analytics for Claude's sophisticated analysis
        company_analytics = {}
        all_companies = list(grouped_chunks.keys())
        
        for msp, qa_list in grouped_chunks.items():
            scores = [qa['score'] for qa in qa_list]
            categories = defaultdict(list)
            
            # Organize by category for deeper analysis
            for qa in qa_list:
                categories[qa['category']].append(qa)
            
            # Calculate comprehensive metrics
            analytics = {
                'overall_avg': round(sum(scores) / len(scores), 2),
                'score_distribution': {
                    '5ì ': len([s for s in scores if s == 5]),
                    '4ì ': len([s for s in scores if s == 4]),
                    '3ì ': len([s for s in scores if s == 3]),
                    '2ì  ì´í•˜': len([s for s in scores if s <= 2])
                },
                'category_performance': {},
                'excellence_areas': [],
                'improvement_areas': [],
                'evidence_quality': {
                    'detailed_responses': len([qa for qa in qa_list if len(qa['answer']) > 150]),
                    'specific_examples': len([qa for qa in qa_list if any(keyword in qa['answer'].lower() 
                                            for keyword in ['í”„ë¡œì íŠ¸', 'ì‚¬ë¡€', 'ê²½í—˜', 'ë…„', 'ê°œì›”', '%', 'ëª…', 'ê±´', 'ì–µ', 'ë§Œ'])]),
                    'total_responses': len(qa_list)
                }
            }
            
            # Category-wise analysis
            for category, cat_qa_list in categories.items():
                if cat_qa_list:
                    cat_scores = [qa['score'] for qa in cat_qa_list]
                    analytics['category_performance'][category] = {
                        'avg_score': round(sum(cat_scores) / len(cat_scores), 2),
                        'response_count': len(cat_qa_list),
                        'excellence_count': len([s for s in cat_scores if s >= 4])
                    }
                    
                    # Identify excellence and improvement areas
                    cat_avg = sum(cat_scores) / len(cat_scores)
                    if cat_avg >= 4.0:
                        analytics['excellence_areas'].append(f"{category} ({cat_avg:.1f}ì )")
                    elif cat_avg <= 3.0:
                        analytics['improvement_areas'].append(f"{category} ({cat_avg:.1f}ì )")
            
            company_analytics[msp] = analytics

        # Create rich, structured context for Claude's analysis
        analysis_context = []
        
        for msp, qa_list in grouped_chunks.items():
            analytics = company_analytics[msp]
            
            # Best evidence selection - prioritize high scores and detailed answers
            sorted_qa = sorted(qa_list, key=lambda x: (x['score'], len(x['answer'])), reverse=True)
            top_evidence = sorted_qa[:6]  # Top 6 pieces of evidence
            
            company_block = f"""
=== {msp} ì¢…í•© ë¶„ì„ ===
ì „ì²´ í‰ê· : {analytics['overall_avg']}/5ì  | ì‘ë‹µ ìˆ˜: {analytics['evidence_quality']['total_responses']}ê°œ

ì ìˆ˜ ë¶„í¬:
- ìš°ìˆ˜(5ì ): {analytics['score_distribution']['5ì ']}ê°œ
- ì–‘í˜¸(4ì ): {analytics['score_distribution']['4ì ']}ê°œ  
- ë³´í†µ(3ì ): {analytics['score_distribution']['3ì ']}ê°œ
- ë¯¸í¡(2ì  ì´í•˜): {analytics['score_distribution']['2ì  ì´í•˜']}ê°œ

ì¹´í…Œê³ ë¦¬ë³„ ì„±ê³¼:
{chr(10).join([f"- {cat}: {perf['avg_score']:.1f}ì  ({perf['response_count']}ê°œ ì‘ë‹µ)" 
              for cat, perf in analytics['category_performance'].items()])}

ê°•ì  ì˜ì—­: {', '.join(analytics['excellence_areas']) if analytics['excellence_areas'] else 'íŠ¹ì´ì‚¬í•­ ì—†ìŒ'}
ê°œì„  ì˜ì—­: {', '.join(analytics['improvement_areas']) if analytics['improvement_areas'] else 'íŠ¹ì´ì‚¬í•­ ì—†ìŒ'}

êµ¬ì²´ì„± ì§€í‘œ:
- ìƒì„¸ ë‹µë³€: {analytics['evidence_quality']['detailed_responses']}/{analytics['evidence_quality']['total_responses']}ê°œ
- êµ¬ì²´ì  ì‚¬ë¡€/ìˆ˜ì¹˜: {analytics['evidence_quality']['specific_examples']}/{analytics['evidence_quality']['total_responses']}ê°œ

í•µì‹¬ ê·¼ê±° ìë£Œ:
{chr(10).join([f"[{qa['score']}ì ] {qa['category']} | Q: {qa['question'][:60]}{'...' if len(qa['question']) > 60 else ''}" + 
              f"{chr(10)}    A: {qa['answer'][:200]}{'...' if len(qa['answer']) > 200 else ''}"
              for qa in top_evidence])}
"""
            analysis_context.append(company_block)

        full_context = "\n".join(analysis_context)
        
        # Sophisticated prompt for Claude's analytical reasoning
        prompt = f"""ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ì‹œë‹ˆì–´ í´ë¼ìš°ë“œ ì»¨ì„¤í„´íŠ¸ë¡œì„œ, ë‹¤ìŒ MSP íŒŒíŠ¸ë„ˆì‚¬ í‰ê°€ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì¶”ì²œì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­: "{question}"

{full_context}

=== ì „ë¬¸ê°€ ë¶„ì„ í”„ë ˆì„ì›Œí¬ ===

1. **ìš”êµ¬ì‚¬í•­ ì í•©ì„± ë¶„ì„**
   - ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œì™€ ê° íšŒì‚¬ì˜ ê´€ë ¨ ì—­ëŸ‰ ë§¤ì¹­ë„
   - ë‹¨ìˆœ ì ìˆ˜ê°€ ì•„ë‹Œ ì§ˆë¬¸ ë§¥ë½ì—ì„œì˜ ì‹¤ì œ ì í•©ì„± í‰ê°€

2. **ì—­ëŸ‰ ì‹¬í™” ë¶„ì„**
   - ì¹´í…Œê³ ë¦¬ë³„ ì„±ê³¼ íŒ¨í„´ ë° ê· í˜•ì„± ê²€í† 
   - ìš°ìˆ˜ ì˜ì—­ì˜ ì‹¤ì§ˆì  ì°¨ë³„í™” ìš”ì†Œ ì‹ë³„
   - ì•½ì  ì˜ì—­ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ í‰ê°€

3. **ì¦ê±° ì‹ ë¢°ì„± í‰ê°€**
   - ë‹µë³€ì˜ êµ¬ì²´ì„±ê³¼ ì‹¤ë¬´ ê²½í—˜ ìˆ˜ì¤€ íŒë‹¨
   - ì •ëŸ‰ì  ë°ì´í„° vs ì •ì„±ì  ì„¤ëª…ì˜ ê· í˜•
   - ì¼ê´€ì„± ìˆëŠ” ì „ë¬¸ì„± ì…ì¦ ì—¬ë¶€

4. **ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ ìš”ì†Œ**
   - ê° íšŒì‚¬ ì„ íƒ ì‹œ ì˜ˆìƒë˜ëŠ” ì´ì ê³¼ ì œì•½ì‚¬í•­
   - í”„ë¡œì íŠ¸ ì„±ê³µ ê°€ëŠ¥ì„±ê³¼ ì ì¬ì  ìš°ë ¤ì‚¬í•­

5. **ë¹„êµ ìš°ìœ„ ë¶„ì„**
   - íšŒì‚¬ ê°„ ëª…í™•í•œ ì°¨ë³„í™” í¬ì¸íŠ¸
   - ë™ë“±í•œ ìˆ˜ì¤€ì¼ ê²½ìš°ì˜ ì„¸ë¶€ íŒë‹¨ ê¸°ì¤€

=== ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜ ì¤€ìˆ˜) ===

**ğŸ† 1ìˆœìœ„ ì¶”ì²œ: [íšŒì‚¬ëª…]**
**ì í•©ë„:** â­â­â­â­â­ (5/5)
**ì„ ì • ê·¼ê±°:**
- [êµ¬ì²´ì  ê°•ì ê³¼ ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ì—°ê²°ì  2-3ì¤„]
- [ì°¨ë³„í™” ìš”ì†Œì™€ ê²½ìŸ ìš°ìœ„ 1-2ì¤„]

**í•µì‹¬ ì—­ëŸ‰ ë¶„ì„:**
- ìš°ìˆ˜ ë¶„ì•¼: [ì¹´í…Œê³ ë¦¬] (X.Xì ) - [êµ¬ì²´ì  ê·¼ê±°]
- ê²€ì¦ëœ ì‹¤ì : [êµ¬ì²´ì  ì‚¬ë¡€ë‚˜ ìˆ˜ì¹˜]

**ì„ íƒ ì‹œ ê¸°ëŒ€íš¨ê³¼:** [ì‹¤ë¬´ì  ê´€ì ì˜ ì´ì ]

---

**ğŸ¥ˆ 2ìˆœìœ„ ì¶”ì²œ: [íšŒì‚¬ëª…]**  
**ì í•©ë„:** â­â­â­â­â˜† (4/5)
**ì„ ì • ê·¼ê±°:**
- [1ìˆœìœ„ì™€ ì°¨ë³„í™”ëœ ê°•ì  ì„¤ëª…]
- [íŠ¹ì • ìƒí™©ì—ì„œì˜ ìš°ìœ„ ìš”ì†Œ]

**í•µì‹¬ ì—­ëŸ‰ ë¶„ì„:**
- ìš°ìˆ˜ ë¶„ì•¼: [ì¹´í…Œê³ ë¦¬] (X.Xì ) - [êµ¬ì²´ì  ê·¼ê±°]
- ê³ ë ¤ì‚¬í•­: [ì•½ì ì´ë‚˜ ì œì•½ì‚¬í•­ì´ ìˆë‹¤ë©´]

**ì„ íƒ ì‹œ ê¸°ëŒ€íš¨ê³¼:** [ì‹¤ë¬´ì  ê´€ì ì˜ ì´ì ]

---

**ğŸ“Š ì¢…í•© ë¹„êµ ë¶„ì„**
- **í•µì‹¬ ì°¨ì´ì :** [1ìˆœìœ„ì™€ 2ìˆœìœ„ì˜ ëª…í™•í•œ êµ¬ë¶„ì ]
- **ìƒí™©ë³„ ê¶Œì¥:** [ì–´ë–¤ ìƒí™©ì—ì„œ ê°ê°ì„ ì„ íƒí•´ì•¼ í•˜ëŠ”ì§€]

**ì‹ ë¢°ë„:** ë†’ìŒ (ë¶„ì„ ê·¼ê±°: ì´ {sum(len(qa_list) for qa_list in grouped_chunks.values())}ê°œ í‰ê°€ ë°ì´í„°)

=== ë¶„ì„ ì£¼ì˜ì‚¬í•­ ===
- í‰ê°€ ì ìˆ˜ëŠ” ì°¸ê³ ìš©ì´ë©°, ì§ˆë¬¸ ë§¥ë½ê³¼ì˜ ì‹¤ì œ ì—°ê´€ì„±ì„ ìš°ì„  ê³ ë ¤
- êµ¬ì²´ì  ê·¼ê±°ê°€ ìˆëŠ” ë‚´ìš©ë§Œ ì–¸ê¸‰í•˜ë©°, ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ë¡  ê¸ˆì§€
- ì‹¤ë¬´ì§„ì´ ì˜ì‚¬ê²°ì •ì— í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ
- íšŒì‚¬ëª…ê³¼ í‰ê°€ ë°ì´í„°ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ ë°˜ë“œì‹œ í™•ì¸"""

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Vector search failed: {str(e)}")

    try:
        client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=1200,  # Increased for comprehensive analysis
            temperature=0.1,   # Very low for consistent, analytical reasoning
            system="ë‹¹ì‹ ì€ í´ë¼ìš°ë“œ ë° MSP ì„ ì • ë¶„ì•¼ì˜ ìµœê³  ìˆ˜ì¤€ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë°ì´í„° ê¸°ë°˜ì˜ ë…¼ë¦¬ì  ë¶„ì„ê³¼ ì‹¤ë¬´ì  í†µì°°ë ¥ì„ ê²¸ë¹„í•˜ì—¬, ê³ ê°ì´ ìµœì ì˜ ì˜ì‚¬ê²°ì •ì„ í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”ë˜ê³  ì„¤ë“ë ¥ ìˆëŠ” ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤. ì¶”ìƒì  í‘œí˜„ë³´ë‹¤ëŠ” êµ¬ì²´ì  ê·¼ê±°ì™€ ì‹¤ì§ˆì  ê°€ì¹˜ì— ì§‘ì¤‘í•˜ë©°, ë¶„ì„ì˜ íˆ¬ëª…ì„±ê³¼ ì‹ ë¢°ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ í•©ë‹ˆë‹¤.",
            messages=[{
                "role": "user", 
                "content": prompt
            }]
        )
        
        answer = response.content[0].text.strip()
        
        # Enhanced post-processing for consistency
        professional_terms = {
            "ì„¤ë£¨ì…˜": "ì†”ë£¨ì…˜",
            "êµ¬í˜„": "êµ¬ì¶•", 
            "ë§Œë“¤": "êµ¬ì¶•",
            "ì¢‹ìŠµë‹ˆë‹¤": "ìš°ìˆ˜í•©ë‹ˆë‹¤",
            "ë›°ì–´ë‚©ë‹ˆë‹¤": "ìš°ìˆ˜í•©ë‹ˆë‹¤"
        }
        
        for old_term, new_term in professional_terms.items():
            answer = answer.replace(old_term, new_term)
        
        return {
            "answer": answer,
            "evidence": query_results["metadatas"][0],
            "model_used": "claude-3-haiku-expert-enhanced",
            "analysis_quality": "comprehensive_analytical",
            "companies_analyzed": len(grouped_chunks),
            "total_evidence_points": sum(len(qa_list) for qa_list in grouped_chunks.values()),
            "analytics_summary": {company: analytics['overall_avg'] for company, analytics in company_analytics.items()}
        }
        
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Claude API error: {str(e)}")

def run_msp_recommendation_clova(question: str, min_score: int):
    """
    Original CLOVA-based MSP recommendation function (backup)
    """
    from collections import defaultdict
    import traceback
    from openai import OpenAI
    import json

    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=10
        )
        grouped_chunks = defaultdict(list)
        for meta in query_results["metadatas"][0]:
            if not isinstance(meta.get("answer"), str) or not meta["answer"].strip():
                continue
            if meta["score"] is not None and int(meta["score"]) >= min_score:
                grouped_chunks[meta["msp_name"]].append(
                    f"Q: {meta['question']}\nA: {meta['answer']} (score: {meta['score']})"
                )

        if not grouped_chunks:
            return {"answer": "í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” í‰ê°€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        context_blocks = []
        for msp, qa_list in grouped_chunks.items():
            context_blocks.append(f"[{msp}]\n" + "\n".join(qa_list))

        context = "\n\n".join(context_blocks)
        prompt = (
            f"{context}\n\n"
            f"ìœ„ì˜ Q&A ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ '{question}'ì— ê°€ì¥ ì˜ ë¶€í•©í•˜ëŠ” ìƒìœ„ 2ê°œ íšŒì‚¬ë¥¼ ì„ ì •í•´ ì£¼ì„¸ìš”.\n\n"
            f"[ì£¼ì˜ì‚¬í•­]\n"
            f"- ì¶”ë¡  ê¸ˆì§€: ì£¼ì–´ì§„ ì •ë³´ì— ëª…í™•íˆ ë‚˜íƒ€ë‚˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì •í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ê¸°ëŒ€ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•˜ì§€ ë§ˆì„¸ìš”.\n"
            f"- ì •ë³´ ë¶€ì¡± ì‹œ í•´ë‹¹ íšŒì‚¬ë¥¼ ì œì™¸í•˜ê³ , ëª…í™•í•œ ì—°ê²°ê³ ë¦¬ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì„ ì •í•˜ì„¸ìš”.\n"
            f"- scoreëŠ” ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë³´ì¡° ì§€í‘œì¼ ë¿ì´ë©°, ë°˜ë“œì‹œ ë†’ì€ ì ìˆ˜ê°€ ì§ì ‘ì ì¸ ë‹µë³€ì„ ì˜ë¯¸í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.\n"
            f"- ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì— ìœ ì˜í•˜ì—¬ ì˜¤íƒ€ ì—†ì´ ì‘ì„±í•  ê²ƒ\n\n"
            f"[í‰ê°€ ê¸°ì¤€]\n"
            f"1. ì§ˆë¬¸ì— ëª…ì‹œì ìœ¼ë¡œ ë‹µí•˜ê³  ìˆëŠ”ê°€?\n"
            f"2. ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?\n"
            f"3. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì‚¬ë¡€, ê·¼ê±°ê°€ ìˆëŠ”ê°€?\n"
            f"4. ì ìˆ˜ëŠ” ë³´ì¡°ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê³ , ì‘ë‹µ ë‚´ìš©ì˜ ëª…í™•ì„±ì„ ì¤‘ì‹¬ìœ¼ë¡œ í‰ê°€í•  ê²ƒ\n"
            f"   ì˜ˆ: 'UI/UX' ê´€ë ¨ ì§ˆë¬¸ì˜ ê²½ìš° 'ì‚¬ìš© í¸ì˜ì„±', 'ì¸í„°í˜ì´ìŠ¤', 'ì ‘ê·¼ì„±', 'ì§ê´€ì„±' ë“± í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸\n\n"
            f"[ì œì™¸ ê¸°ì¤€]\n"
            f"- ë³´ì•ˆ, ì„±ëŠ¥, ë°ì´í„° ì²˜ë¦¬ ë“± ìœ ì‚¬ ê°œë…ì€ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µí•˜ì§€ ì•ŠëŠ” í•œ ì œì™¸\n"
            f"- ì¶”ì¸¡, ê¸°ëŒ€ ê¸°ë°˜ í•´ì„, ì ìˆ˜ë§Œì„ ê·¼ê±°ë¡œ í•œ ì„ ì •ì€ ê¸ˆì§€\n"
            f"- DBì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê¸°ì—…ì„ ì„ ì •í•˜ëŠ” ê²ƒì€ ì ˆëŒ€ ê¸ˆì§€\n\n"
            f"[ì‘ë‹µ í˜•ì‹]\n"
            f"- ê° íšŒì‚¬ëª…ì„ **êµµê²Œ** í‘œì‹œí•˜ê³ , ê° íšŒì‚¬ë¥¼ ë³„ë„ì˜ ë‹¨ë½ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.\n"
            f"- ìµœì¢… ì‘ë‹µ ì „ íšŒì‚¬ëª…ì´ msp_nameì´ ë§ëŠ”ì§€ í™•ì‹¤íˆ í™•ì¸ í›„ ì‘ë‹µí•´ ì£¼ì„¸ìš”.\n"
            f"- ì„ ì • ì´ìœ ëŠ” ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ 1~2ë¬¸ì¥ìœ¼ë¡œ ê¸°ìˆ í•˜ì„¸ìš”.\n\n"
            f"ì˜ˆì‹œ:\n"
            f"**A íšŒì‚¬**\n"
            f"- ì„ ì • ì´ìœ : AI ì „ë¬¸ ì¸ë ¥ ë¹„ìœ¨ì´ ë†’ê³ , í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í”„ë¡œì íŠ¸ ì‚¬ë¡€ë¥¼ ì–¸ê¸‰í•˜ë©° 5ì ì„ ë°›ìŒ\n\n"
            f"**B íšŒì‚¬**\n"
            f"- ì„ ì • ì´ìœ : OCR ê¸°ìˆ  ê´€ë ¨ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, í•´ë‹¹ ì§ˆë¬¸ì— ëª…í™•íˆ ì‘ë‹µí•˜ê³  4ì ì„ ê¸°ë¡í•¨\n\n"
            f"**ê¸°íƒ€ íšŒì‚¬**\n"
            f"- ê´€ë ¨ í‚¤ì›Œë“œ ë¶€ì¬, ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì  ë‹µë³€ ì—†ìŒ ë“± ëª…í™•í•œ ê·¼ê±°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê°„ë‹¨íˆ ì–¸ê¸‰"
        )
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Vector search failed: {str(e)}")

    CLOVA_API_KEY = os.getenv("CLOVA_API_KEY_OPENAI")
    API_URL = "https://clovastudio.stream.ntruss.com/v1/openai"
    client = OpenAI(api_key=CLOVA_API_KEY, base_url=API_URL)
    model = "HCX-005"

    try:
        clova_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "í´ë¼ìš°ë“œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¬¸ì¥ìœ¼ë¡œ, ì˜¤íƒˆì ì—†ì´ ì •í™•í•œ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. ë¬¸ì¥ì€ ê°„ê²°í•˜ë©´ì„œë„ ìì—°ìŠ¤ëŸ½ê³ , ì¼ê´€ë˜ë©° ì‹ ë¢°ê° ìˆê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            top_p=0.6,
            temperature=0.3,
            max_tokens=500
        )
        if not clova_response.choices or not clova_response.choices[0].message.content:
            answer = ""
        else:
            answer = clova_response.choices[0].message.content.strip()
        answer = answer.replace("ì„¤ë£¨ì…˜", "ì†”ë£¨ì…˜")
        return {"answer": answer, "raw": clova_response.model_dump(), "evidence": query_results["metadatas"][0]}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"HyperCLOVA error: {str(e)}")
    
# Information summary function (for Information domain)
def run_msp_information_summary(question: str):
    import traceback
    from openai import OpenAI
    import json

    query = question
    msp_name = extract_msp_name(question)

    all_results = collection.get(include=["metadatas"])
    all_msp_names = [meta.get("msp_name", "") for meta in all_results["metadatas"] if meta.get("msp_name")]

    matches = get_close_matches(msp_name, all_msp_names, n=1, cutoff=0.6)
    if not matches:
        return {"answer": "ì§ˆë¬¸í•˜ì‹  íšŒì‚¬ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "advanced": False}
    best_match = matches[0]

    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=8
        )
        filtered_chunks = [c for c in query_results["metadatas"][0] if c.get("answer") and c.get("question") and c.get("msp_name") == best_match]
        if not filtered_chunks:
            return {"answer": "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "advanced": False}

        answer_blocks = []
        for chunk in filtered_chunks:
            if not chunk.get("answer") or not chunk.get("question"):
                continue
            answer_blocks.append(f"Q: {chunk['question']}\nA: {chunk['answer']}")

        context = "\n\n".join(answer_blocks)
        prompt = (
            f"ë‹¤ìŒì€ MSP íŒŒíŠ¸ë„ˆì‚¬ ê´€ë ¨ ì¸í„°ë·° Q&A ëª¨ìŒì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ì‘ë‹µí•´ ì£¼ì„¸ìš”.\n"
            f"ì‚¬ìš©ì ì§ˆë¬¸: \"{question}\"\n\n"
            f"{context}\n\n"
            f"[ì‘ë‹µ ì§€ì¹¨]\n"
            f"- ì‹¤ì œ Q&Aì— ê¸°ë°˜í•´ ìš”ì•½í•˜ê±°ë‚˜ ì¢…í•©ì ìœ¼ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\n"
            f"- ì—†ëŠ” ì •ë³´ë¥¼ ì¶”ë¡ í•˜ê±°ë‚˜ ê¾¸ë©°ë‚´ì§€ ë§ˆì„¸ìš”.\n"
            f"- ì§ˆë¬¸ê³¼ ë‹¤ë¥¸ íƒ€ íšŒì‚¬ì˜ ì •ë³´ë¥¼ ì ˆëŒ€ë¡œ ì–µì§€ë¡œ ë¼ì›Œë§ì¶”ì§€ ë§ˆì„¸ìš”."
            f"- ê°€ëŠ¥í•œ í•œ ê°„ê²°í•˜ë©´ì„œë„ ì‹ ë¢°ë„ ìˆëŠ” í‘œí˜„ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
        )
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Vector search failed: {str(e)}")

    CLOVA_API_KEY = os.getenv("CLOVA_API_KEY_OPENAI")
    API_URL = "https://clovastudio.stream.ntruss.com/v1/openai"
    client = OpenAI(api_key=CLOVA_API_KEY, base_url=API_URL)
    model = "HCX-005"

    try:
        clova_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ì •í™•í•œ ì •ë³´ì— ê¸°ë°˜í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ í•´ì£¼ì„¸ìš”. ì˜¤íƒˆì ì—†ì´ ëª…í™•í•˜ê³  ì¼ê´€ëœ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            top_p=0.6,
            temperature=0.3,
            max_tokens=500
        )
        if not clova_response.choices or not clova_response.choices[0].message.content:
            answer = ""
        else:
            answer = clova_response.choices[0].message.content.strip()
        answer = answer.replace("ì„¤ë£¨ì…˜", "ì†”ë£¨ì…˜")
        return {"answer": answer, "raw": clova_response.model_dump(), "advanced": False, "evidence": filtered_chunks}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"HyperCLOVA error: {str(e)}")
    
def run_msp_information_summary_claude(question: str):
    """Direct Claude version without Perplexity"""
    import traceback
    
    query = question
    msp_name = extract_msp_name(question)

    all_results = collection.get(include=["metadatas"])
    all_msp_names = [meta.get("msp_name", "") for meta in all_results["metadatas"] if meta.get("msp_name")]

    matches = get_close_matches(msp_name, all_msp_names, n=1, cutoff=0.6)
    if not matches:
        return {"answer": "ì§ˆë¬¸í•˜ì‹  íšŒì‚¬ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "advanced": False}
    best_match = matches[0]

    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=8
        )
        filtered_chunks = [c for c in query_results["metadatas"][0] if c.get("answer") and c.get("question") and c.get("msp_name") == best_match]
        if not filtered_chunks:
            return {"answer": "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "advanced": False}

        answer_blocks = []
        for chunk in filtered_chunks:
            if not chunk.get("answer") or not chunk.get("question"):
                continue
            answer_blocks.append(f"Q: {chunk['question']}\nA: {chunk['answer']}")

        context = "\n\n".join(answer_blocks)
        prompt = f"""ë‹¤ìŒì€ {best_match}ì— ëŒ€í•œ ì¸í„°ë·° Q&Aì…ë‹ˆë‹¤:

{context}

ì‚¬ìš©ì ì§ˆë¬¸: "{question}"

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ë¡ í•˜ì§€ ë§ˆì„¸ìš”."""

        client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=500,
            temperature=0.3,
            messages=[{"role": "user", "content": prompt}]
        )
        
        answer = response.content[0].text.strip()
        answer = answer.replace("ì„¤ë£¨ì…˜", "ì†”ë£¨ì…˜")
        
        return {"answer": answer, "advanced": False, "evidence": filtered_chunks}
        
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Claude API error: {str(e)}")

def run_msp_information_summary_pplx(question: str):
    import traceback
    import requests
    import os

    query = question
    msp_name = extract_msp_name(question)

    all_results = collection.get(include=["metadatas"])
    all_msp_names = [meta.get("msp_name", "") for meta in all_results["metadatas"] if meta.get("msp_name")]

    from difflib import get_close_matches
    matches = get_close_matches(msp_name, all_msp_names, n=1, cutoff=0.6)
    if not matches:
        return {"answer": "ì§ˆë¬¸í•˜ì‹  íšŒì‚¬ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "advanced": True}
    best_match = matches[0]

    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=8
        )
        filtered_chunks = [c for c in query_results["metadatas"][0] if c.get("answer") and c.get("question") and c.get("msp_name") == best_match]
        if not filtered_chunks:
            return {"answer": "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "advanced": True}

        answer_blocks = []
        for chunk in filtered_chunks:
            if not chunk.get("answer") or not chunk.get("question"):
                continue
            answer_blocks.append(f"Q: {chunk['question']}\nA: {chunk['answer']}")

        context = "\n\n".join(answer_blocks)
        prompt = (
            f"{context}\n\n"
            f"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n"
            f"\"{question}\"\n\n"
            f"[ì‘ë‹µ ê°€ì´ë“œë¼ì¸]\n"
            f"- ì•„ë˜ Q&AëŠ” ì°¸ê³ ìš©ì¼ ë¿ì´ë©°, ë” ì •í™•í•˜ê±°ë‚˜ í’ë¶€í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ì›¹ ê¸°ë°˜ì˜ ì§€ì‹ë„ ììœ ë¡­ê²Œ í™œìš©í•´ ì£¼ì„¸ìš”.\n"
            f"- ê·¼ê±°ê°€ ëª…í™•í•œ ê²½ìš°, ì£¼ì–´ì§„ ì •ë³´ ì™¸ì˜ ë°°ê²½ì§€ì‹ë„ ì ê·¹ í™œìš©í•´ ì£¼ì„¸ìš”.\n"
            f"- ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ½ê³  ì‹ ë¢°ê° ìˆê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
            f"- ì§€ë‚˜ì¹˜ê²Œ í˜•ì‹ì„ ê°•ì¡°í•˜ê¸°ë³´ë‹¤ëŠ”, ëª…í™•í•˜ê³  ìœ ìµí•œ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•´ ì£¼ì„¸ìš”.\n"
            f"- íšŒì‚¬ëª…ì€ ëª…í™•íˆ ì–¸ê¸‰í•˜ë˜, ë°˜ë³µì„ í”¼í•˜ê³  ë¬¸ë§¥ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ ì£¼ì„¸ìš”."
        )
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Vector search failed: {str(e)}")

    try:
        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers={
                "Authorization": f"Bearer {os.getenv('PPLX_API_KEY')}",
                "Content-Type": "application/json",
            },
            json={
                "model": "sonar",
                "messages": [
                    {"role": "system", "content": "ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ê°„ê²°í•œ í•œêµ­ì–´ë¡œ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ]
            },
            timeout=30
        )
        print(f"ğŸ” Claude API status: {response.status_code}")
        print(f"ğŸ“¦ Claude API raw response: {response.text}")
        if response.status_code == 200:
            import re
            result = response.json()
            answer = result["choices"][0]["message"]["content"].strip()
            # Clean up answer
            answer = re.sub(r"\[Q&A\]", "", answer)
            answer = re.sub(r"Q[:ï¼š]", "", answer)
            answer = re.sub(r"A[:ï¼š]", "", answer)
            answer = answer.strip()
            answer = re.sub(r"\[\d+\]", "", answer)  # Remove [1], [2], etc.
            return {"answer": answer, "advanced": True, "evidence": filtered_chunks}
        else:
            return {"answer": "Claude API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "advanced": True}
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Claude API error: {str(e)}")

def extract_msp_name(question: str) -> str:
    from openai import OpenAI
    import os

    CLOVA_API_KEY = os.getenv("CLOVA_API_KEY_OPENAI")
    API_URL = "https://clovastudio.stream.ntruss.com/v1/openai"
    client = OpenAI(api_key=CLOVA_API_KEY, base_url=API_URL)
    model = "HCX-005"

    prompt = (
        f"ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ì‹¤ì œ í´ë¼ìš°ë“œ MSP íŒŒíŠ¸ë„ˆì‚¬ì˜ ì´ë¦„ë§Œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”. ë¬¸ì¥ ì „ì²´ë¥¼ ì¶œë ¥í•˜ì§€ ë§ê³ , íšŒì‚¬ëª…ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        f"[ì˜ˆì‹œ]\n"
        f"ì§ˆë¬¸: 'ITCEN CLOITì— ëŒ€í•´ ì•Œë ¤ì¤˜'\nì‘ë‹µ: ITCEN CLOIT\n"
        f"ì§ˆë¬¸: 'Lominì˜ AI ì—­ëŸ‰ì€?'\nì‘ë‹µ: Lomin\n"
        f"ì§ˆë¬¸: 'ë² ìŠ¤í•€ê¸€ë¡œë²Œì˜ MLOps ì‚¬ë¡€ëŠ”?'\nì‘ë‹µ: ë² ìŠ¤í•€ê¸€ë¡œë²Œ\n"
        f"ì§ˆë¬¸: '{question}'\n"
        f"ì‘ë‹µ:"
    )

    try:
        clova_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ì§ˆë¬¸ì—ì„œ í´ë¼ìš°ë“œ MSP íšŒì‚¬ ì´ë¦„ë§Œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”. ë¬¸ì¥ì€ ì ˆëŒ€ ì‘ì„±í•˜ì§€ ë§ê³ , íšŒì‚¬ëª…ë§Œ ë‹¨ë…ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆ: ë² ìŠ¤í•€ê¸€ë¡œë²Œ"},
                {"role": "user", "content": prompt}
            ],
            top_p=0.6,
            temperature=0.3,
            max_tokens=20
        )
        raw = clova_response.choices[0].message.content.strip()
        print(f"ğŸ” Extracted raw MSP name: {raw}")
        return raw
    except Exception as e:
        print(f"âŒ Error extracting MSP name: {e}")
        return ""

def run_msp_news_summary_clova(question: str):
    import urllib.parse
    import urllib.request
    import traceback

    msp_name = extract_msp_name(question)
    if not msp_name:
        return {"answer": "íšŒì‚¬ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "advanced": True}

    # Get vector DB information for the MSP
    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=10
        )
        db_chunks = [
            f"Q: {chunk['question']}\nA: {chunk['answer']}"
            for chunk in query_results["metadatas"][0]
            if chunk.get("msp_name") == msp_name and chunk.get("question") and chunk.get("answer")
        ][:5]
        db_context = "\n\n".join(db_chunks)
    except Exception as e:
        db_context = ""

    try:
        query = urllib.parse.quote(msp_name)
        url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=10&sort=sim"
        headers = {
            "X-Naver-Client-Id": os.getenv("NAVER_CLIENT_ID"),
            "X-Naver-Client-Secret": os.getenv("NAVER_CLIENT_SECRET")
        }
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req) as response:
            if response.status != 200:
                raise Exception(f"Naver API Error: {response.status}")
            news_data = json.loads(response.read().decode("utf-8"))

        url_web = f"https://openapi.naver.com/v1/search/webkr.json?query={query}&display=3&sort=sim"
        req_web = urllib.request.Request(url_web, headers=headers)
        with urllib.request.urlopen(req_web) as response_web:
            if response_web.status != 200:
                raise Exception(f"Naver Web API Error: {response_web.status}")
            web_data = json.loads(response_web.read().decode("utf-8"))

        if "items" not in news_data or not news_data["items"]:
            return {"answer": f"{msp_name}ì— ëŒ€í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "advanced": True}

        article_summaries = "\n".join(
            f"- ì œëª©: {item['title'].replace('<b>', '').replace('</b>', '')}\n  ìš”ì•½: {item['description'].replace('<b>', '').replace('</b>', '')}"
            for item in news_data["items"]
        )

        web_summaries = "\n".join(
            f"- ì œëª©: {item['title'].replace('<b>', '').replace('</b>', '')}\n  ìš”ì•½: {item['description'].replace('<b>', '').replace('</b>', '')}"
            for item in web_data.get("items", [])
        )

        prompt = (
            f"ë‹¤ìŒì€ í´ë¼ìš°ë“œ MSP ê¸°ì—… '{msp_name}'ì— ëŒ€í•œ ë‰´ìŠ¤ ê¸°ì‚¬, ì›¹ ë¬¸ì„œ, ì¸í„°ë·° Q&A ìš”ì•½ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì‘ë‹µí•´ ì£¼ì„¸ìš”.\n"
            f"ì‚¬ìš©ì ì§ˆë¬¸: \"{question}\"\n\n"
            f"[DB ê¸°ë°˜ ì •ë³´]\n{db_context}\n\n"
            f"[ë‰´ìŠ¤ ê¸°ì‚¬ ìš”ì•½]\n{article_summaries}\n\n"
            f"[ì›¹ ë¬¸ì„œ ìš”ì•½]\n{web_summaries}\n\n"
            f"[ì‘ë‹µ ì§€ì¹¨]\n"
            f"- ê¸°ì‚¬, ì›¹ ë¬¸ì„œ, ì¸í„°ë·° Q&A ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.\n"
            f"- ì—†ëŠ” ì •ë³´ë¥¼ ê¾¸ë©°ë‚´ê±°ë‚˜ ì¶”ë¡ í•˜ì§€ ë§ˆì„¸ìš”.\n"
            f"- ê¸°ì—…ì˜ ìˆ˜ìƒ ì‹¤ì , í˜‘ì—…, íˆ¬ì, ì¸ë ¥ êµ¬ì„± ë“± í•µì‹¬ ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”."
        )

        CLOVA_API_KEY = os.getenv("CLOVA_API_KEY_OPENAI")
        API_URL = "https://clovastudio.stream.ntruss.com/v1/openai"
        from openai import OpenAI
        client = OpenAI(api_key=CLOVA_API_KEY, base_url=API_URL)
        model = "HCX-005"

        clova_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ë‹µì„ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            top_p=0.6,
            temperature=0.3,
            max_tokens=500
        )
        answer = clova_response.choices[0].message.content.strip()
        answer = answer.replace("ì„¤ë£¨ì…˜", "ì†”ë£¨ì…˜")
        return {"answer": answer, "advanced": True, "evidence": news_data["items"], "web_evidence": web_data.get("items", [])}
    except Exception as e:
        traceback.print_exc()
        return {"answer": f"ë‰´ìŠ¤ ê¸°ë°˜ ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}", "advanced": True}

def run_msp_news_summary_claude(question: str):
    """
    Enhanced version with more data for Claude
    """
    import urllib.parse
    import urllib.request
    import traceback
    import anthropic
    import os

    msp_name = extract_msp_name(question)
    if not msp_name:
        return {"answer": "íšŒì‚¬ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "advanced": True}

    # Enhanced vector DB search - get more relevant data for Claude
    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=15
        )
        db_chunks = [
            f"Q: {chunk['question']}\nA: {chunk['answer']} (ì ìˆ˜: {chunk.get('score', 'N/A')}/5)"
            for chunk in query_results["metadatas"][0]
            if chunk.get("msp_name") == msp_name and chunk.get("question") and chunk.get("answer")
        ][:8]
        db_context = "\n\n".join(db_chunks)
    except Exception as e:
        db_context = ""

    try:
        # Enhanced API calls - get more comprehensive data
        query = urllib.parse.quote(msp_name)
        
        # Get more news articles for better coverage
        url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=15&sort=sim"
        headers = {
            "X-Naver-Client-Id": os.getenv("NAVER_CLIENT_ID"),
            "X-Naver-Client-Secret": os.getenv("NAVER_CLIENT_SECRET")
        }
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req) as response:
            if response.status != 200:
                raise Exception(f"Naver API Error: {response.status}")
            news_data = json.loads(response.read().decode("utf-8"))

        # Get more web documents for comprehensive view
        url_web = f"https://openapi.naver.com/v1/search/webkr.json?query={query}&display=7&sort=sim"
        req_web = urllib.request.Request(url_web, headers=headers)
        with urllib.request.urlopen(req_web) as response_web:
            if response_web.status != 200:
                raise Exception(f"Naver Web API Error: {response_web.status}")
            web_data = json.loads(response_web.read().decode("utf-8"))

        if "items" not in news_data or not news_data["items"]:
            return {"answer": f"{msp_name}ì— ëŒ€í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "advanced": True}

        # Enhanced data cleaning and formatting for Claude
        def clean_text(text):
            return text.replace('<b>', '').replace('</b>', '').replace('&quot;', '"').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')

        # Structured news formatting with more metadata
        news_items = []
        for i, item in enumerate(news_data["items"][:12], 1):  # Top 12 most relevant
            title = clean_text(item.get('title', ''))
            desc = clean_text(item.get('description', ''))
            pub_date = item.get('pubDate', '')[:10] if item.get('pubDate') else 'N/A'
            
            if title and desc:  # Only include substantial content
                news_items.append(f"{i}. [{pub_date}] {title}\n   ì„¸ë¶€ë‚´ìš©: {desc}")

        # Structured web formatting with quality filtering
        web_items = []
        for i, item in enumerate(web_data.get("items", [])[:5], 1):  # Top 5 web docs
            title = clean_text(item.get('title', ''))
            desc = clean_text(item.get('description', ''))
            
            if title and desc and len(desc) > 50:  # Filter for substantial content
                web_items.append(f"{i}. {title}\n   ìš”ì•½: {desc}")

        article_text = "\n\n".join(news_items)
        web_text = "\n\n".join(web_items)

        # Enhanced prompt designed for Claude's analytical capabilities
        prompt = f"""ë‹¤ìŒì€ í´ë¼ìš°ë“œ MSP íŒŒíŠ¸ë„ˆì‚¬ '{msp_name}'ì— ëŒ€í•œ ì¢…í•© ì •ë³´ì…ë‹ˆë‹¤. ì´ ë‹¤ì–‘í•œ ì •ë³´ì›ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ì „ë¬¸ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: "{question}"

=== ë‚´ë¶€ í‰ê°€ ë°ì´í„° (ê°€ì¥ ì‹ ë¢°ë„ ë†’ìŒ) ===
{db_context}

=== ë‰´ìŠ¤ ê¸°ì‚¬ ì •ë³´ ({len(news_items)}ê°œ ìµœì‹  ê¸°ì‚¬) ===
{article_text}

=== ì›¹ ë¬¸ì„œ ì •ë³´ ({len(web_items)}ê°œ ê´€ë ¨ ë¬¸ì„œ) ===
{web_text}

=== ì „ë¬¸ê°€ ìˆ˜ì¤€ ë¶„ì„ ì§€ì¹¨ ===
1. **ì •ë³´ í†µí•© ë¶„ì„**: ë‚´ë¶€ í‰ê°€, ë‰´ìŠ¤, ì›¹ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ê· í˜•ì¡íŒ ì‹œê° ì œê³µ
2. **ì‹ ë¢°ë„ ìš°ì„ ìˆœìœ„**: ë‚´ë¶€ í‰ê°€ ë°ì´í„° â†’ ê³µì‹ ë‰´ìŠ¤ â†’ ì›¹ ë¬¸ì„œ ìˆœìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì ìš©
3. **êµ¬ì²´ì  ê·¼ê±° ì œì‹œ**: 
   - í‰ê°€ ì ìˆ˜ë‚˜ êµ¬ì²´ì  ìˆ˜ì¹˜ ìš°ì„  ì–¸ê¸‰
   - ì‹œê¸°ë³„ ë³€í™”ë‚˜ ìµœê·¼ ë™í–¥ íŒŒì•…
   - ê²½ìŸì‚¬ ëŒ€ë¹„ ì°¨ë³„í™” ìš”ì†Œ ì‹ë³„
4. **ì‹¤ë¬´ì  ê´€ì **: ì‹¤ì œ ê³ ê°/íŒŒíŠ¸ë„ˆ ê´€ì ì—ì„œ ì˜ë¯¸ìˆëŠ” ì •ë³´ ìš°ì„  ì •ë¦¬
5. **ê°ê´€ì  ê· í˜•**: ê°•ì ê³¼ ê°œì„ ì˜ì—­ì„ ëª¨ë‘ ê³ ë ¤í•œ ê³µì •í•œ í‰ê°€

ì‘ë‹µ í˜•ì‹: ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, ë§ˆì¼€íŒ… í‘œí˜„ë³´ë‹¤ëŠ” íŒ©íŠ¸ì™€ ë°ì´í„° ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•´ì£¼ì„¸ìš”."""

    except Exception as e:
        traceback.print_exc()
        return {"answer": f"ë‰´ìŠ¤ ê¸°ë°˜ ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}", "advanced": True}

    # Enhanced Claude API call with optimized parameters
    try:
        client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=1000,
            temperature=0.2,  # Lower for more factual, analytical responses
            system="ë‹¹ì‹ ì€ 10ë…„ ì´ìƒ ê²½ë ¥ì˜ í´ë¼ìš°ë“œ ë° MSP ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì •ë³´ì›ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ ê°ê´€ì ì´ê³  ì‹¤ìš©ì ì¸ í†µì°°ì„ ì œê³µí•˜ë©°, êµ¬ì²´ì  ê·¼ê±°ì™€ ë°ì´í„°ì— ê¸°ë°˜í•œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ í‰ê°€ë¥¼ ì¤‘ì‹œí•©ë‹ˆë‹¤.",
            messages=[{
                "role": "user", 
                "content": prompt
            }]
        )
        
        answer = response.content[0].text.strip()
        
        # Enhanced post-processing for professional consistency
        answer = answer.replace("ì„¤ë£¨ì…˜", "ì†”ë£¨ì…˜")
        answer = answer.replace("í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤", "í´ë¼ìš°ë“œ ì†”ë£¨ì…˜")
        
        return {
            "answer": answer, 
            "advanced": True, 
            "evidence": news_data["items"][:12], 
            "web_evidence": web_data.get("items", [])[:5],
            "model_used": "claude-3-haiku-enhanced",
            "data_summary": {
                "news_articles": len(news_items),
                "web_documents": len(web_items),
                "internal_qa_pairs": len(db_chunks),
                "total_sources": len(news_items) + len(web_items) + len(db_chunks)
            }
        }
        
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Claude API error: {str(e)}")
