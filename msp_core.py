from fpdf import FPDF
from datetime import datetime
from fastapi import HTTPException
from typing import Any
import requests
import json
import uuid
from difflib import get_close_matches
from vector_writer import clova_embedding
import os
import chromadb
from chromadb import PersistentClient

# Embedding and collection setup
def query_embed(text: str):
    return clova_embedding(text)

CHROMA_PATH = os.path.abspath("chroma_store")
client = PersistentClient(path=CHROMA_PATH)
collection = client.get_or_create_collection("msp_chunks")

def run_msp_recommendation(question: str, min_score: int):
    from collections import defaultdict
    import traceback
    from openai import OpenAI
    import json

    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=10
        )
        grouped_chunks = defaultdict(list)
        for meta in query_results["metadatas"][0]:
            if not isinstance(meta.get("answer"), str) or not meta["answer"].strip():
                continue
            if meta["score"] is not None and int(meta["score"]) >= min_score:
                grouped_chunks[meta["msp_name"]].append(
                    f"Q: {meta['question']}\nA: {meta['answer']} (score: {meta['score']})"
                )

        if not grouped_chunks:
            return {"answer": "í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” í‰ê°€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        context_blocks = []
        for msp, qa_list in grouped_chunks.items():
            context_blocks.append(f"[{msp}]\n" + "\n".join(qa_list))

        context = "\n\n".join(context_blocks)
        prompt = (
            f"{context}\n\n"
            f"ìœ„ì˜ Q&A ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ '{question}'ì— ê°€ì¥ ì˜ ë¶€í•©í•˜ëŠ” ìƒìœ„ 2ê°œ íšŒì‚¬ë¥¼ ì„ ì •í•´ ì£¼ì„¸ìš”.\n\n"
            f"[ì£¼ì˜ì‚¬í•­]\n"
            f"- ì¶”ë¡  ê¸ˆì§€: ì£¼ì–´ì§„ ì •ë³´ì— ëª…í™•íˆ ë‚˜íƒ€ë‚˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì •í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ê¸°ëŒ€ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•˜ì§€ ë§ˆì„¸ìš”.\n"
            f"- ì •ë³´ ë¶€ì¡± ì‹œ í•´ë‹¹ íšŒì‚¬ë¥¼ ì œì™¸í•˜ê³ , ëª…í™•í•œ ì—°ê²°ê³ ë¦¬ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì„ ì •í•˜ì„¸ìš”.\n"
            f"- scoreëŠ” ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë³´ì¡° ì§€í‘œì¼ ë¿ì´ë©°, ë°˜ë“œì‹œ ë†’ì€ ì ìˆ˜ê°€ ì§ì ‘ì ì¸ ë‹µë³€ì„ ì˜ë¯¸í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.\n"
            f"- ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì— ìœ ì˜í•˜ì—¬ ì˜¤íƒ€ ì—†ì´ ì‘ì„±í•  ê²ƒ\n\n"
            f"[í‰ê°€ ê¸°ì¤€]\n"
            f"1. ì§ˆë¬¸ì— ëª…ì‹œì ìœ¼ë¡œ ë‹µí•˜ê³  ìˆëŠ”ê°€?\n"
            f"2. ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?\n"
            f"3. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì‚¬ë¡€, ê·¼ê±°ê°€ ìˆëŠ”ê°€?\n"
            f"4. ì ìˆ˜ëŠ” ë³´ì¡°ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê³ , ì‘ë‹µ ë‚´ìš©ì˜ ëª…í™•ì„±ì„ ì¤‘ì‹¬ìœ¼ë¡œ í‰ê°€í•  ê²ƒ\n"
            f"   ì˜ˆ: 'UI/UX' ê´€ë ¨ ì§ˆë¬¸ì˜ ê²½ìš° 'ì‚¬ìš© í¸ì˜ì„±', 'ì¸í„°í˜ì´ìŠ¤', 'ì ‘ê·¼ì„±', 'ì§ê´€ì„±' ë“± í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸\n\n"
            f"[ì œì™¸ ê¸°ì¤€]\n"
            f"- ë³´ì•ˆ, ì„±ëŠ¥, ë°ì´í„° ì²˜ë¦¬ ë“± ìœ ì‚¬ ê°œë…ì€ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µí•˜ì§€ ì•ŠëŠ” í•œ ì œì™¸\n"
            f"- ì¶”ì¸¡, ê¸°ëŒ€ ê¸°ë°˜ í•´ì„, ì ìˆ˜ë§Œì„ ê·¼ê±°ë¡œ í•œ ì„ ì •ì€ ê¸ˆì§€\n"
            f"- DBì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê¸°ì—…ì„ ì„ ì •í•˜ëŠ” ê²ƒì€ ì ˆëŒ€ ê¸ˆì§€\n\n"
            f"[ì‘ë‹µ í˜•ì‹]\n"
            f"- ê° íšŒì‚¬ëª…ì„ **êµµê²Œ** í‘œì‹œí•˜ê³ , ê° íšŒì‚¬ë¥¼ ë³„ë„ì˜ ë‹¨ë½ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.\n"
            f"- ìµœì¢… ì‘ë‹µ ì „ íšŒì‚¬ëª…ì´ msp_nameì´ ë§ëŠ”ì§€ í™•ì‹¤íˆ í™•ì¸ í›„ ì‘ë‹µí•´ ì£¼ì„¸ìš”.\n"
            f"- ì„ ì • ì´ìœ ëŠ” ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ 1~2ë¬¸ì¥ìœ¼ë¡œ ê¸°ìˆ í•˜ì„¸ìš”.\n\n"
            f"ì˜ˆì‹œ:\n"
            f"**A íšŒì‚¬**\n"
            f"- ì„ ì • ì´ìœ : AI ì „ë¬¸ ì¸ë ¥ ë¹„ìœ¨ì´ ë†’ê³ , í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í”„ë¡œì íŠ¸ ì‚¬ë¡€ë¥¼ ì–¸ê¸‰í•˜ë©° 5ì ì„ ë°›ìŒ\n\n"
            f"**B íšŒì‚¬**\n"
            f"- ì„ ì • ì´ìœ : OCR ê¸°ìˆ  ê´€ë ¨ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, í•´ë‹¹ ì§ˆë¬¸ì— ëª…í™•íˆ ì‘ë‹µí•˜ê³  4ì ì„ ê¸°ë¡í•¨\n\n"
            f"**ê¸°íƒ€ íšŒì‚¬**\n"
            f"- ê´€ë ¨ í‚¤ì›Œë“œ ë¶€ì¬, ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì  ë‹µë³€ ì—†ìŒ ë“± ëª…í™•í•œ ê·¼ê±°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê°„ë‹¨íˆ ì–¸ê¸‰"
        )
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Vector search failed: {str(e)}")

    CLOVA_API_KEY = os.getenv("CLOVA_API_KEY_OPENAI")
    API_URL = "https://clovastudio.stream.ntruss.com/v1/openai"
    client = OpenAI(api_key=CLOVA_API_KEY, base_url=API_URL)
    model = "HCX-005"

    try:
        clova_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "í´ë¼ìš°ë“œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¬¸ì¥ìœ¼ë¡œ, ì˜¤íƒˆì ì—†ì´ ì •í™•í•œ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. ë¬¸ì¥ì€ ê°„ê²°í•˜ë©´ì„œë„ ìì—°ìŠ¤ëŸ½ê³ , ì¼ê´€ë˜ë©° ì‹ ë¢°ê° ìˆê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            top_p=0.6,
            temperature=0.3,
            max_tokens=500
        )
        if not clova_response.choices or not clova_response.choices[0].message.content:
            answer = ""
        else:
            answer = clova_response.choices[0].message.content.strip()
        answer = answer.replace("ì„¤ë£¨ì…˜", "ì†”ë£¨ì…˜")
        return {"answer": answer, "raw": clova_response.model_dump(), "evidence": query_results["metadatas"][0]}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"HyperCLOVA error: {str(e)}")
    
# Information summary function (for Information domain)
def run_msp_information_summary(question: str):
    import traceback
    from openai import OpenAI
    import json

    query = question
    msp_name = extract_msp_name(question)

    all_results = collection.get(include=["metadatas"])
    all_msp_names = [meta.get("msp_name", "") for meta in all_results["metadatas"] if meta.get("msp_name")]

    matches = get_close_matches(msp_name, all_msp_names, n=1, cutoff=0.6)
    if not matches:
        return {"answer": "ì§ˆë¬¸í•˜ì‹  íšŒì‚¬ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "advanced": False}
    best_match = matches[0]

    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=8
        )
        filtered_chunks = [c for c in query_results["metadatas"][0] if c.get("answer") and c.get("question") and c.get("msp_name") == best_match]
        if not filtered_chunks:
            return {"answer": "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "advanced": False}

        answer_blocks = []
        for chunk in filtered_chunks:
            if not chunk.get("answer") or not chunk.get("question"):
                continue
            answer_blocks.append(f"Q: {chunk['question']}\nA: {chunk['answer']}")

        context = "\n\n".join(answer_blocks)
        prompt = (
            f"ë‹¤ìŒì€ MSP íŒŒíŠ¸ë„ˆì‚¬ ê´€ë ¨ ì¸í„°ë·° Q&A ëª¨ìŒì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ì‘ë‹µí•´ ì£¼ì„¸ìš”.\n"
            f"ì‚¬ìš©ì ì§ˆë¬¸: \"{question}\"\n\n"
            f"{context}\n\n"
            f"[ì‘ë‹µ ì§€ì¹¨]\n"
            f"- ì‹¤ì œ Q&Aì— ê¸°ë°˜í•´ ìš”ì•½í•˜ê±°ë‚˜ ì¢…í•©ì ìœ¼ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\n"
            f"- ì—†ëŠ” ì •ë³´ë¥¼ ì¶”ë¡ í•˜ê±°ë‚˜ ê¾¸ë©°ë‚´ì§€ ë§ˆì„¸ìš”.\n"
            f"- ì§ˆë¬¸ê³¼ ë‹¤ë¥¸ íƒ€ íšŒì‚¬ì˜ ì •ë³´ë¥¼ ì ˆëŒ€ë¡œ ì–µì§€ë¡œ ë¼ì›Œë§ì¶”ì§€ ë§ˆì„¸ìš”."
            f"- ê°€ëŠ¥í•œ í•œ ê°„ê²°í•˜ë©´ì„œë„ ì‹ ë¢°ë„ ìˆëŠ” í‘œí˜„ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
        )
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Vector search failed: {str(e)}")

    CLOVA_API_KEY = os.getenv("CLOVA_API_KEY_OPENAI")
    API_URL = "https://clovastudio.stream.ntruss.com/v1/openai"
    client = OpenAI(api_key=CLOVA_API_KEY, base_url=API_URL)
    model = "HCX-005"

    try:
        clova_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ì •í™•í•œ ì •ë³´ì— ê¸°ë°˜í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ í•´ì£¼ì„¸ìš”. ì˜¤íƒˆì ì—†ì´ ëª…í™•í•˜ê³  ì¼ê´€ëœ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            top_p=0.6,
            temperature=0.3,
            max_tokens=500
        )
        if not clova_response.choices or not clova_response.choices[0].message.content:
            answer = ""
        else:
            answer = clova_response.choices[0].message.content.strip()
        answer = answer.replace("ì„¤ë£¨ì…˜", "ì†”ë£¨ì…˜")
        return {"answer": answer, "raw": clova_response.model_dump(), "advanced": False, "evidence": filtered_chunks}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"HyperCLOVA error: {str(e)}")

def run_msp_information_summary_claude(question: str):
    import traceback
    import requests
    import os

    query = question
    msp_name = extract_msp_name(question)

    all_results = collection.get(include=["metadatas"])
    all_msp_names = [meta.get("msp_name", "") for meta in all_results["metadatas"] if meta.get("msp_name")]

    from difflib import get_close_matches
    matches = get_close_matches(msp_name, all_msp_names, n=1, cutoff=0.6)
    if not matches:
        return {"answer": "ì§ˆë¬¸í•˜ì‹  íšŒì‚¬ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "advanced": True}
    best_match = matches[0]

    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=8
        )
        filtered_chunks = [c for c in query_results["metadatas"][0] if c.get("answer") and c.get("question") and c.get("msp_name") == best_match]
        if not filtered_chunks:
            return {"answer": "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "advanced": True}

        answer_blocks = []
        for chunk in filtered_chunks:
            if not chunk.get("answer") or not chunk.get("question"):
                continue
            answer_blocks.append(f"Q: {chunk['question']}\nA: {chunk['answer']}")

        context = "\n\n".join(answer_blocks)
        prompt = (
            f"{context}\n\n"
            f"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n"
            f"\"{question}\"\n\n"
            f"[ì‘ë‹µ ê°€ì´ë“œë¼ì¸]\n"
            f"- ì•„ë˜ Q&AëŠ” ì°¸ê³ ìš©ì¼ ë¿ì´ë©°, ë” ì •í™•í•˜ê±°ë‚˜ í’ë¶€í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ì›¹ ê¸°ë°˜ì˜ ì§€ì‹ë„ ììœ ë¡­ê²Œ í™œìš©í•´ ì£¼ì„¸ìš”.\n"
            f"- ê·¼ê±°ê°€ ëª…í™•í•œ ê²½ìš°, ì£¼ì–´ì§„ ì •ë³´ ì™¸ì˜ ë°°ê²½ì§€ì‹ë„ ì ê·¹ í™œìš©í•´ ì£¼ì„¸ìš”.\n"
            f"- ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ½ê³  ì‹ ë¢°ê° ìˆê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
            f"- ì§€ë‚˜ì¹˜ê²Œ í˜•ì‹ì„ ê°•ì¡°í•˜ê¸°ë³´ë‹¤ëŠ”, ëª…í™•í•˜ê³  ìœ ìµí•œ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•´ ì£¼ì„¸ìš”.\n"
            f"- íšŒì‚¬ëª…ì€ ëª…í™•íˆ ì–¸ê¸‰í•˜ë˜, ë°˜ë³µì„ í”¼í•˜ê³  ë¬¸ë§¥ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ ì£¼ì„¸ìš”."
        )
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Vector search failed: {str(e)}")

    try:
        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers={
                "Authorization": f"Bearer {os.getenv('PPLX_API_KEY')}",
                "Content-Type": "application/json",
            },
            json={
                "model": "sonar",
                "messages": [
                    {"role": "system", "content": "ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ê°„ê²°í•œ í•œêµ­ì–´ë¡œ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ]
            },
            timeout=30
        )
        print(f"ğŸ” Claude API status: {response.status_code}")
        print(f"ğŸ“¦ Claude API raw response: {response.text}")
        if response.status_code == 200:
            import re
            result = response.json()
            answer = result["choices"][0]["message"]["content"].strip()
            # Clean up answer
            answer = re.sub(r"\[Q&A\]", "", answer)
            answer = re.sub(r"Q[:ï¼š]", "", answer)
            answer = re.sub(r"A[:ï¼š]", "", answer)
            answer = answer.strip()
            answer = re.sub(r"\[\d+\]", "", answer)  # Remove [1], [2], etc.
            return {"answer": answer, "advanced": True, "evidence": filtered_chunks}
        else:
            return {"answer": "Claude API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "advanced": True}
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Claude API error: {str(e)}")

def extract_msp_name(question: str) -> str:
    from openai import OpenAI
    import os

    CLOVA_API_KEY = os.getenv("CLOVA_API_KEY_OPENAI")
    API_URL = "https://clovastudio.stream.ntruss.com/v1/openai"
    client = OpenAI(api_key=CLOVA_API_KEY, base_url=API_URL)
    model = "HCX-005"

    prompt = (
        f"ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ì‹¤ì œ í´ë¼ìš°ë“œ MSP íŒŒíŠ¸ë„ˆì‚¬ì˜ ì´ë¦„ë§Œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”. ë¬¸ì¥ ì „ì²´ë¥¼ ì¶œë ¥í•˜ì§€ ë§ê³ , íšŒì‚¬ëª…ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        f"[ì˜ˆì‹œ]\n"
        f"ì§ˆë¬¸: 'ITCEN CLOITì— ëŒ€í•´ ì•Œë ¤ì¤˜'\nì‘ë‹µ: ITCEN CLOIT\n"
        f"ì§ˆë¬¸: 'Lominì˜ AI ì—­ëŸ‰ì€?'\nì‘ë‹µ: Lomin\n"
        f"ì§ˆë¬¸: 'ë² ìŠ¤í•€ê¸€ë¡œë²Œì˜ MLOps ì‚¬ë¡€ëŠ”?'\nì‘ë‹µ: ë² ìŠ¤í•€ê¸€ë¡œë²Œ\n"
        f"ì§ˆë¬¸: '{question}'\n"
        f"ì‘ë‹µ:"
    )

    try:
        clova_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ì§ˆë¬¸ì—ì„œ í´ë¼ìš°ë“œ MSP íšŒì‚¬ ì´ë¦„ë§Œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”. ë¬¸ì¥ì€ ì ˆëŒ€ ì‘ì„±í•˜ì§€ ë§ê³ , íšŒì‚¬ëª…ë§Œ ë‹¨ë…ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆ: ë² ìŠ¤í•€ê¸€ë¡œë²Œ"},
                {"role": "user", "content": prompt}
            ],
            top_p=0.6,
            temperature=0.3,
            max_tokens=20
        )
        raw = clova_response.choices[0].message.content.strip()
        print(f"ğŸ” Extracted raw MSP name: {raw}")
        return raw
    except Exception as e:
        print(f"âŒ Error extracting MSP name: {e}")
        return ""

def run_msp_news_summary_clova(question: str):
    import urllib.parse
    import urllib.request
    import traceback

    msp_name = extract_msp_name(question)
    if not msp_name:
        return {"answer": "íšŒì‚¬ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "advanced": True}

    # Get vector DB information for the MSP
    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=10
        )
        db_chunks = [
            f"Q: {chunk['question']}\nA: {chunk['answer']}"
            for chunk in query_results["metadatas"][0]
            if chunk.get("msp_name") == msp_name and chunk.get("question") and chunk.get("answer")
        ][:5]
        db_context = "\n\n".join(db_chunks)
    except Exception as e:
        db_context = ""

    try:
        query = urllib.parse.quote(msp_name)
        url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=10&sort=sim"
        headers = {
            "X-Naver-Client-Id": os.getenv("NAVER_CLIENT_ID"),
            "X-Naver-Client-Secret": os.getenv("NAVER_CLIENT_SECRET")
        }
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req) as response:
            if response.status != 200:
                raise Exception(f"Naver API Error: {response.status}")
            news_data = json.loads(response.read().decode("utf-8"))

        url_web = f"https://openapi.naver.com/v1/search/webkr.json?query={query}&display=3&sort=sim"
        req_web = urllib.request.Request(url_web, headers=headers)
        with urllib.request.urlopen(req_web) as response_web:
            if response_web.status != 200:
                raise Exception(f"Naver Web API Error: {response_web.status}")
            web_data = json.loads(response_web.read().decode("utf-8"))

        if "items" not in news_data or not news_data["items"]:
            return {"answer": f"{msp_name}ì— ëŒ€í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "advanced": True}

        article_summaries = "\n".join(
            f"- ì œëª©: {item['title'].replace('<b>', '').replace('</b>', '')}\n  ìš”ì•½: {item['description'].replace('<b>', '').replace('</b>', '')}"
            for item in news_data["items"]
        )

        web_summaries = "\n".join(
            f"- ì œëª©: {item['title'].replace('<b>', '').replace('</b>', '')}\n  ìš”ì•½: {item['description'].replace('<b>', '').replace('</b>', '')}"
            for item in web_data.get("items", [])
        )

        prompt = (
            f"ë‹¤ìŒì€ í´ë¼ìš°ë“œ MSP ê¸°ì—… '{msp_name}'ì— ëŒ€í•œ ë‰´ìŠ¤ ê¸°ì‚¬, ì›¹ ë¬¸ì„œ, ì¸í„°ë·° Q&A ìš”ì•½ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì‘ë‹µí•´ ì£¼ì„¸ìš”.\n"
            f"ì‚¬ìš©ì ì§ˆë¬¸: \"{question}\"\n\n"
            f"[DB ê¸°ë°˜ ì •ë³´]\n{db_context}\n\n"
            f"[ë‰´ìŠ¤ ê¸°ì‚¬ ìš”ì•½]\n{article_summaries}\n\n"
            f"[ì›¹ ë¬¸ì„œ ìš”ì•½]\n{web_summaries}\n\n"
            f"[ì‘ë‹µ ì§€ì¹¨]\n"
            f"- ê¸°ì‚¬, ì›¹ ë¬¸ì„œ, ì¸í„°ë·° Q&A ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.\n"
            f"- ì—†ëŠ” ì •ë³´ë¥¼ ê¾¸ë©°ë‚´ê±°ë‚˜ ì¶”ë¡ í•˜ì§€ ë§ˆì„¸ìš”.\n"
            f"- ê¸°ì—…ì˜ ìˆ˜ìƒ ì‹¤ì , í˜‘ì—…, íˆ¬ì, ì¸ë ¥ êµ¬ì„± ë“± í•µì‹¬ ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”."
        )

        CLOVA_API_KEY = os.getenv("CLOVA_API_KEY")
        API_URL = "https://clovastudio.stream.ntruss.com/v1/openai"
        from openai import OpenAI
        client = OpenAI(api_key=CLOVA_API_KEY, base_url=API_URL)
        model = "HCX-005"

        clova_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ë‹µì„ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            top_p=0.6,
            temperature=0.3,
            max_tokens=500
        )
        answer = clova_response.choices[0].message.content.strip()
        answer = answer.replace("ì„¤ë£¨ì…˜", "ì†”ë£¨ì…˜")
        return {"answer": answer, "advanced": True, "evidence": news_data["items"], "web_evidence": web_data.get("items", [])}
    except Exception as e:
        traceback.print_exc()
        return {"answer": f"ë‰´ìŠ¤ ê¸°ë°˜ ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}", "advanced": True}
