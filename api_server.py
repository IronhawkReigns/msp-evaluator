import os
from dotenv import load_dotenv
load_dotenv()
from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse, RedirectResponse
from fastapi.requests import Request
import requests
from vector_writer import run_from_msp_name
from admin_protected import router as admin_router, manager

# Register user_loader at import time to avoid "Missing user_loader callback" error
@manager.user_loader()
def load_user(username: str):
    from admin_protected import User
    env_username = os.getenv("ADMIN_USERNAME")
    if username == env_username:
        return User(name=username)

import chromadb
from chromadb import PersistentClient

app = FastAPI()

app.include_router(admin_router)
print("ğŸ“¦ admin router included")

class CompanyInput(BaseModel):
    name: str

def query_embed(text: str):
    from vector_writer import clova_embedding
    return clova_embedding(text)

@app.post("/run/{msp_name}")
def run_msp_vector_pipeline(msp_name: str):
    try:
        run_from_msp_name(msp_name)
        return {"message": f"Vector DB update completed for {msp_name}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Serve static files
app.mount("/static", StaticFiles(directory="static"), name="static")


@app.get("/ui")
def serve_ui(request: Request):
    try:
        user = manager(request)
        return FileResponse("static/index.html")
    except:
        return RedirectResponse(url="/login?next=/ui")


# Serve query UI
@app.get("/query")
def serve_query_ui():
    return FileResponse("static/query.html")

# Load ChromaDB
CHROMA_PATH = os.path.abspath("chroma_store")
client = PersistentClient(path=CHROMA_PATH)
collection = client.get_or_create_collection("msp_chunks")

@app.get("/ui/data")
def get_filtered_chunks(question: str = None, min_score: int = 0):
    # Return flat format for public UI compatibility
    results = collection.get(include=["metadatas"])
    data = []
    for meta in results["metadatas"]:
        if not isinstance(meta.get("answer"), str) or not meta["answer"].strip():
            continue
        if question and question != meta["question"]:
            continue
        if meta["score"] is not None and int(meta["score"]) >= min_score:
            data.append({
                "msp_name": meta["msp_name"],
                "question": meta["question"],
                "score": meta["score"],
                "answer": meta["answer"]
            })
    return JSONResponse(content=data)

# Flat data endpoint for public UI
@app.get("/ui/data_flat")
def get_flat_chunks(question: str = None, min_score: int = 0):
    results = collection.get(include=["metadatas"])
    data = []
    for meta in results["metadatas"]:
        if not isinstance(meta.get("answer"), str) or not meta["answer"].strip():
            continue
        if question and question != meta["question"]:
            continue
        if meta["score"] is not None and int(meta["score"]) >= min_score:
            data.append({
                "msp_name": meta["msp_name"],
                "question": meta["question"],
                "score": meta["score"],
                "answer": meta["answer"]
            })
    return JSONResponse(content=data)

# Query/Ask endpoint
@app.post("/query/ask")
async def ask_question(request: Request):
    from collections import defaultdict

    body = await request.json()
    question = body.get("question")
    min_score = int(body.get("min_score", 0))
    if not question:
        raise HTTPException(status_code=400, detail="Missing question")

    # Retrieve top 3 relevant chunks from ChromaDB
    import traceback
    try:
        query_vector = query_embed(question)
        query_results = collection.query(
            query_embeddings=[query_vector],
            n_results=10
        )
        grouped_chunks = defaultdict(list)
        for meta in query_results["metadatas"][0]:
            if not isinstance(meta.get("answer"), str) or not meta["answer"].strip():
                continue
            if meta["score"] is not None and int(meta["score"]) >= min_score:
                grouped_chunks[meta["msp_name"]].append(
                    f"Q: {meta['question']}\nA: {meta['answer']} (score: {meta['score']})"
                )

        if not grouped_chunks:
            return {"answer": "í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” í‰ê°€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        context_blocks = []
        for msp, qa_list in grouped_chunks.items():
            context_blocks.append(f"[{msp}]\n" + "\n".join(qa_list))

        context = "\n\n".join(context_blocks)
        prompt = (
            f"{context}\n\n"
            f"ìœ„ì˜ Q&A ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ '{question}'ì— ê°€ì¥ ì˜ ë¶€í•©í•˜ëŠ” ìƒìœ„ 2ê°œ íšŒì‚¬ë¥¼ ì„ ì •í•´ ì£¼ì„¸ìš”.\n\n"
            
            f"[ì£¼ì˜ì‚¬í•­]\n"
            f"- ì¶”ë¡  ê¸ˆì§€: ì£¼ì–´ì§„ ì •ë³´ì— ëª…í™•íˆ ë‚˜íƒ€ë‚˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì •í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ê¸°ëŒ€ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•˜ì§€ ë§ˆì„¸ìš”.\n"
            f"- ì •ë³´ ë¶€ì¡± ì‹œ í•´ë‹¹ íšŒì‚¬ë¥¼ ì œì™¸í•˜ê³ , ëª…í™•í•œ ì—°ê²°ê³ ë¦¬ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì„ ì •í•˜ì„¸ìš”.\n"
            f"- scoreëŠ” ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë³´ì¡° ì§€í‘œì¼ ë¿ì´ë©°, ë°˜ë“œì‹œ ë†’ì€ ì ìˆ˜ê°€ ì§ì ‘ì ì¸ ë‹µë³€ì„ ì˜ë¯¸í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.\n"
            f"- ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì— ìœ ì˜í•˜ì—¬ ì˜¤íƒ€ ì—†ì´ ì‘ì„±í•  ê²ƒ\n\n"

            f"[í‰ê°€ ê¸°ì¤€]\n"
            f"1. ì§ˆë¬¸ì— ëª…ì‹œì ìœ¼ë¡œ ë‹µí•˜ê³  ìˆëŠ”ê°€?\n"
            f"2. ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?\n"
            f"3. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì‚¬ë¡€, ê·¼ê±°ê°€ ìˆëŠ”ê°€?\n"
            f"4. ì ìˆ˜ëŠ” ë³´ì¡°ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê³ , ì‘ë‹µ ë‚´ìš©ì˜ ëª…í™•ì„±ì„ ì¤‘ì‹¬ìœ¼ë¡œ í‰ê°€í•  ê²ƒ\n"
            f"   ì˜ˆ: 'UI/UX' ê´€ë ¨ ì§ˆë¬¸ì˜ ê²½ìš° 'ì‚¬ìš© í¸ì˜ì„±', 'ì¸í„°í˜ì´ìŠ¤', 'ì ‘ê·¼ì„±', 'ì§ê´€ì„±' ë“± í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸\n\n"

            f"[ì œì™¸ ê¸°ì¤€]\n"
            f"- ë³´ì•ˆ, ì„±ëŠ¥, ë°ì´í„° ì²˜ë¦¬ ë“± ìœ ì‚¬ ê°œë…ì€ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µí•˜ì§€ ì•ŠëŠ” í•œ ì œì™¸\n"
            f"- ì¶”ì¸¡, ê¸°ëŒ€ ê¸°ë°˜ í•´ì„, ì ìˆ˜ë§Œì„ ê·¼ê±°ë¡œ í•œ ì„ ì •ì€ ê¸ˆì§€\n"
            f"- DBì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê¸°ì—…ì„ ì„ ì •í•˜ëŠ” ê²ƒì€ ì ˆëŒ€ ê¸ˆì§€\n\n"

            f"[ì‘ë‹µ í˜•ì‹]\n"
            f"- ê° íšŒì‚¬ëª…ì„ **êµµê²Œ** í‘œì‹œí•˜ê³ , ê° íšŒì‚¬ë¥¼ ë³„ë„ì˜ ë‹¨ë½ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.\n"
            f"- ìµœì¢… ì‘ë‹µ ì „ íšŒì‚¬ëª…ì´ msp_nameì´ ë§ëŠ”ì§€ í™•ì‹¤íˆ í™•ì¸ í›„ ì‘ë‹µí•´ ì£¼ì„¸ìš”.\n"
            f"- ì„ ì • ì´ìœ ëŠ” ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ 1~2ë¬¸ì¥ìœ¼ë¡œ ê¸°ìˆ í•˜ì„¸ìš”.\n\n"
            f"ì˜ˆì‹œ:\n"
            f"**A íšŒì‚¬**\n"
            f"- ì„ ì • ì´ìœ : AI ì „ë¬¸ ì¸ë ¥ ë¹„ìœ¨ì´ ë†’ê³ , í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í”„ë¡œì íŠ¸ ì‚¬ë¡€ë¥¼ ì–¸ê¸‰í•˜ë©° 5ì ì„ ë°›ìŒ\n\n"
            f"**B íšŒì‚¬**\n"
            f"- ì„ ì • ì´ìœ : OCR ê¸°ìˆ  ê´€ë ¨ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, í•´ë‹¹ ì§ˆë¬¸ì— ëª…í™•íˆ ì‘ë‹µí•˜ê³  4ì ì„ ê¸°ë¡í•¨\n\n"
            f"**ê¸°íƒ€ íšŒì‚¬**\n"
            f"- ê´€ë ¨ í‚¤ì›Œë“œ ë¶€ì¬, ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì  ë‹µë³€ ì—†ìŒ ë“± ëª…í™•í•œ ê·¼ê±°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê°„ë‹¨íˆ ì–¸ê¸‰"
        )
    except Exception as e:
        print("=== Vector search failed ===")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Vector search failed: {str(e)}")

    # Call HyperCLOVA API (new style using OpenAI client)
    from openai import OpenAI
    CLOVA_API_KEY = os.getenv("CLOVA_API_KEY")
    API_URL = "https://clovastudio.stream.ntruss.com/v1/openai"
    client = OpenAI(api_key=CLOVA_API_KEY, base_url=API_URL)
    model = "HCX-005"

    import json
    try:
        clova_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "í´ë¼ìš°ë“œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¬¸ì¥ìœ¼ë¡œ, ì˜¤íƒˆì ì—†ì´ ì •í™•í•œ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. ë¬¸ì¥ì€ ê°„ê²°í•˜ë©´ì„œë„ ìì—°ìŠ¤ëŸ½ê³ , ì¼ê´€ë˜ë©° ì‹ ë¢°ê° ìˆê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            top_p=0.6,
            temperature=0.2,
            max_tokens=500
        )
        try:
            if not clova_response.choices or not clova_response.choices[0].message.content:
                print("CLOVA ì‘ë‹µ ì—†ìŒ ë˜ëŠ” content í•„ë“œ ë¹„ì–´ ìˆìŒ")
                answer = ""
            else:
                answer = clova_response.choices[0].message.content.strip()
            answer = answer.replace("ì„¤ë£¨ì…˜", "ì†”ë£¨ì…˜")
            # Debug
            print("==== CLOVA RAW RESPONSE ====")
            print(json.dumps(clova_response.model_dump(), indent=2, ensure_ascii=False))
            return {"answer": answer or "", "raw": clova_response.model_dump()}
        except Exception as e:
            print("CLOVA ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸:", str(e))
            raise HTTPException(status_code=500, detail=f"ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"HyperCLOVA error: {str(e)}")
# Add protected /admin route using same login logic as /ui
@app.get("/admin")
def serve_admin_ui(request: Request):
    try:
        user = manager(request)
        return FileResponse("static/admin.html")
    except Exception as e:
        return RedirectResponse(url="/login?next=/admin")
@app.get("/")
def serve_main_page():
    return FileResponse("static/main.html")
